{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad38bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting google-cloud-dialogflow\n",
      "  Downloading google_cloud_dialogflow-2.41.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: openai in c:\\python311\\lib\\site-packages (1.35.9)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (2.32.3)\n",
      "Collecting azure-cognitiveservices-language-luis\n",
      "  Downloading azure_cognitiveservices_language_luis-0.7.1-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-dialogflow)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\python311\\lib\\site-packages (from google-cloud-dialogflow) (2.38.0)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-cloud-dialogflow)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\python311\\lib\\site-packages (from google-cloud-dialogflow) (4.25.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python311\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python311\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\python311\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\python311\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\python311\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\python311\\lib\\site-packages (from openai) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Collecting msrest>=0.6.21 (from azure-cognitiveservices-language-luis)\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting azure-common~=1.1 (from azure-cognitiveservices-language-luis)\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0 (from azure-cognitiveservices-language-luis)\n",
      "  Downloading azure_mgmt_core-1.5.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting azure-core>=1.31.0 (from azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-luis)\n",
      "  Downloading azure_core-1.33.0-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-dialogflow)\n",
      "  Downloading googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-dialogflow) (1.65.4)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-dialogflow)\n",
      "  Downloading grpcio_status-1.72.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-dialogflow) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-dialogflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-dialogflow) (4.9)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting isodate>=0.6.0 (from msrest>=0.6.21->azure-cognitiveservices-language-luis)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\python311\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-language-luis) (2.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\python311\\lib\\site-packages (from azure-core>=1.31.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-luis) (1.16.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-cloud-dialogflow)\n",
      "  Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-dialogflow)\n",
      "  Downloading grpcio-1.72.0rc1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-dialogflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python311\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-language-luis) (3.2.2)\n",
      "Downloading google_cloud_dialogflow-2.41.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.0/2.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading azure_cognitiveservices_language_luis-0.7.1-py2.py3-none-any.whl (81 kB)\n",
      "Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Downloading azure_mgmt_core-1.5.0-py3-none-any.whl (30 kB)\n",
      "Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading azure_core-1.33.0-py3-none-any.whl (207 kB)\n",
      "Downloading googleapis_common_protos-1.69.2-py3-none-any.whl (293 kB)\n",
      "Downloading grpcio_status-1.72.0rc1-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading grpcio-1.72.0rc1-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.3 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.6/4.3 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.4/4.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: azure-common, protobuf, isodate, grpcio, proto-plus, googleapis-common-protos, azure-core, msrest, grpcio-status, google-api-core, azure-mgmt-core, azure-cognitiveservices-language-luis, google-cloud-dialogflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.4\n",
      "    Uninstalling protobuf-4.25.4:\n",
      "      Successfully uninstalled protobuf-4.25.4\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.65.4\n",
      "    Uninstalling grpcio-1.65.4:\n",
      "      Successfully uninstalled grpcio-1.65.4\n",
      "Successfully installed azure-cognitiveservices-language-luis-0.7.1 azure-common-1.1.28 azure-core-1.33.0 azure-mgmt-core-1.5.0 google-api-core-2.24.2 google-cloud-dialogflow-2.41.1 googleapis-common-protos-1.69.2 grpcio-1.72.0rc1 grpcio-status-1.72.0rc1 isodate-0.7.2 msrest-0.7.1 proto-plus-1.26.1 protobuf-6.30.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (c:\\Python311\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-cpu 2.19.0 requires keras>=3.5.0, but you have keras 2.12.0 which is incompatible.\n",
      "tensorflow-cpu 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
      "tensorflow-cpu 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.30.2 which is incompatible.\n",
      "tensorflow-cpu 2.19.0 requires tensorboard~=2.19.0, but you have tensorboard 2.12.3 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 6.30.2 which is incompatible.\n",
      "wandb 0.19.7 requires protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0; sys_platform != \"linux\", but you have protobuf 6.30.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install google-cloud-dialogflow openai requests azure-cognitiveservices-language-luis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb95ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [12/Apr/2025 19:03:26] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [12/Apr/2025 19:08:01] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [12/Apr/2025 19:08:13] \"GET / HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/webhook', methods=['POST'])\n",
    "def webhook():\n",
    "    req = request.get_json(silent=True, force=True)\n",
    "    \n",
    "    intent = req.get(\"queryResult\", {}).get(\"intent\", {}).get(\"displayName\", \"\")\n",
    "    \n",
    "    if intent == \"Course Duration\":\n",
    "        fulfillment_text = \"Our undergraduate programs are 4 years long, and postgraduate ones are 2 years.\"\n",
    "    elif intent == \"Admission Process\":\n",
    "        fulfillment_text = \"You can apply online through our official website. The process includes an entrance test and interview.\"\n",
    "    elif intent == \"Contact Information\":\n",
    "        fulfillment_text = \"You can reach us at info@college.edu or call +91-1234567890.\"\n",
    "    else:\n",
    "        fulfillment_text = \"I'm not sure how to answer that. Could you rephrase?\"\n",
    "    \n",
    "    return jsonify({\n",
    "        \"fulfillmentText\": fulfillment_text\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000, debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4da246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! I'm GPT. Type 'exit' or 'quit' to end the chat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def chat_with_gpt(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"].strip()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Chatbot: Hello! I'm GPT. Type 'exit' or 'quit' to end the chat.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
    "            print(\"Chatbot: Goodbye! \")\n",
    "            break\n",
    "\n",
    "        response = chat_with_gpt(user_input)\n",
    "        print(\"Chatbot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa5804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# dictionary of intents and corresponding responses\n",
    "intents = {\n",
    "    \"greeting\": [\"Hello!\", \"Hi there!\", \"Hey! How can I help you today?\"],\n",
    "    \"goodbye\": [\"Goodbye!\", \"See you later!\", \"Bye! Take care!\"],\n",
    "    \"thanks\": [\"You're welcome!\", \"Happy to help!\", \"No problem!\"],\n",
    "    \"unknown\": [\"Sorry, I didn't understand that.\", \"Can you rephrase that?\", \"I'm not sure what you mean.\"]\n",
    "}\n",
    "\n",
    "def chatbot_response(user_input):\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    if any(word in user_input for word in [\"hello\", \"hi\", \"hey\"]):\n",
    "        return random.choice(intents[\"greeting\"])\n",
    "\n",
    "    elif any(word in user_input for word in [\"bye\", \"goodbye\", \"see you\"]):\n",
    "        return random.choice(intents[\"goodbye\"])\n",
    "\n",
    "    elif any(word in user_input for word in [\"thanks\", \"thank you\"]):\n",
    "        return random.choice(intents[\"thanks\"])\n",
    "\n",
    "    else:\n",
    "        return random.choice(intents[\"unknown\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Chatbot: Hello! I'm your assistant. Type 'exit' to quit.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        # Exit condition\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Get chatbot response\n",
    "        response = chatbot_response(user_input)\n",
    "        print(\"Chatbot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "intents = {\n",
    "    \"greeting\": [\"Hello!\", \"Hi there!\", \"Hey! How can I help you today?\"],\n",
    "    \"goodbye\": [\"Goodbye!\", \"See you later!\", \"Bye! Take care!\"],\n",
    "    \"thanks\": [\"You're welcome!\", \"Happy to help!\", \"No problem!\"],\n",
    "    \"weather\": [\"Sorry, I cannot check the weather right now.\", \"I can't provide weather information.\", \"I don't have access to weather updates.\"],\n",
    "    \"unknown\": [\"Sorry, I didn't understand that.\", \"Can you rephrase that?\", \"I'm not sure what you mean.\"]\n",
    "}\n",
    "\n",
    "\n",
    "def get_intent_from_input(user_input):\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    \n",
    "    if any(word in user_input for word in [\"hello\", \"hi\", \"hey\", \"greetings\"]):\n",
    "        return \"greeting\"\n",
    "    elif any(word in user_input for word in [\"bye\", \"goodbye\", \"see you\"]):\n",
    "        return \"goodbye\"\n",
    "    elif any(word in user_input for word in [\"thanks\", \"thank you\"]):\n",
    "        return \"thanks\"\n",
    "    elif any(word in user_input for word in [\"weather\", \"forecast\", \"rain\", \"temperature\"]):\n",
    "        return \"weather\"\n",
    "    else:\n",
    "        return \"unknown\"  \n",
    "\n",
    "# Function to get chatbot response based on the recognized intent\n",
    "def chatbot_response(user_input):\n",
    "    intent = get_intent_from_input(user_input)\n",
    "    \n",
    "    if intent == \"greeting\":\n",
    "        return random.choice(intents[\"greeting\"])\n",
    "    elif intent == \"goodbye\":\n",
    "        return random.choice(intents[\"goodbye\"])\n",
    "    elif intent == \"thanks\":\n",
    "        return random.choice(intents[\"thanks\"])\n",
    "    elif intent == \"weather\":\n",
    "        return random.choice(intents[\"weather\"])\n",
    "    else:\n",
    "        return random.choice(intents[\"unknown\"])\n",
    "\n",
    "# Main function to handle the chat loop\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Chatbot: Hello! I'm your assistant. Type 'exit' to quit.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        # Exit condition\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Get chatbot response based on user input\n",
    "        response = chatbot_response(user_input)\n",
    "        print(\"Chatbot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969a3629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Aspect                 Google Dialogflow  \\\n",
      "0    Setup & Integration                   Easy, Web-based   \n",
      "1            Ease of Use     Simple, limited customization   \n",
      "2     Intent Recognition  High accuracy for common intents   \n",
      "3    Response Generation              Predefined responses   \n",
      "4  Performance & Latency                 Fast, cloud-based   \n",
      "5          Customization                           Limited   \n",
      "6                Pricing    Free tier, usage-based pricing   \n",
      "7    Community & Support          Strong, Google ecosystem   \n",
      "\n",
      "                             Rasa NLU                     Microsoft LUIS  \\\n",
      "0       Requires installation & setup                    Easy, via Azure   \n",
      "1        Requires technical knowledge   Moderate, Azure knowledge needed   \n",
      "2             Very high, customizable    High, limited for niche domains   \n",
      "3                 Highly customizable       Predefined, backend required   \n",
      "4       Fast, depends on server setup             Fast, depends on Azure   \n",
      "5                           Very high                           Moderate   \n",
      "6  Free, enterprise pricing available     Free tier, usage-based pricing   \n",
      "7        Active open-source community  Large, within Microsoft ecosystem   \n",
      "\n",
      "                                         OpenAI GPT  \n",
      "0                        Easy API-based integration  \n",
      "1                  Very easy, but less customizable  \n",
      "2  High for conversations, low for specific intents  \n",
      "3                Excellent conversational responses  \n",
      "4                     Moderate, depends on API load  \n",
      "5                                      Very limited  \n",
      "6                         Pay-per-use, no free tier  \n",
      "7                            Active, OpenAI support  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data for the comparison table\n",
    "data = {\n",
    "    \"Aspect\": [\n",
    "        \"Setup & Integration\", \"Ease of Use\", \"Intent Recognition\", \n",
    "        \"Response Generation\", \"Performance & Latency\", \"Customization\", \n",
    "        \"Pricing\", \"Community & Support\"\n",
    "    ],\n",
    "    \"Google Dialogflow\": [\n",
    "        \"Easy, Web-based\", \"Simple, limited customization\", \"High accuracy for common intents\",\n",
    "        \"Predefined responses\", \"Fast, cloud-based\", \"Limited\", \n",
    "        \"Free tier, usage-based pricing\", \"Strong, Google ecosystem\"\n",
    "    ],\n",
    "    \"Rasa NLU\": [\n",
    "        \"Requires installation & setup\", \"Requires technical knowledge\", \"Very high, customizable\",\n",
    "        \"Highly customizable\", \"Fast, depends on server setup\", \"Very high\", \n",
    "        \"Free, enterprise pricing available\", \"Active open-source community\"\n",
    "    ],\n",
    "    \"Microsoft LUIS\": [\n",
    "        \"Easy, via Azure\", \"Moderate, Azure knowledge needed\", \"High, limited for niche domains\",\n",
    "        \"Predefined, backend required\", \"Fast, depends on Azure\", \"Moderate\", \n",
    "        \"Free tier, usage-based pricing\", \"Large, within Microsoft ecosystem\"\n",
    "    ],\n",
    "    \"OpenAI GPT\": [\n",
    "        \"Easy API-based integration\", \"Very easy, but less customizable\", \"High for conversations, low for specific intents\",\n",
    "        \"Excellent conversational responses\", \"Moderate, depends on API load\", \"Very limited\", \n",
    "        \"Pay-per-use, no free tier\", \"Active, OpenAI support\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying the table\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3dd197",
   "metadata": {},
   "source": [
    "Setup and Integration:\n",
    "    Google Dialogflow:\n",
    "\n",
    "    Setup: Easy to set up with a user-friendly web interface. It provides APIs to interact programmatically.\n",
    "\n",
    "    Integration: Well-documented API that allows you to integrate easily with many platforms (e.g., web, mobile, social media).\n",
    "\n",
    "    Rasa NLU:\n",
    "\n",
    "    Setup: Requires installation of Rasa and setup on a server or locally. More customizable, but requires more technical effort to set up.\n",
    "\n",
    "    Integration: You need to manually configure the integration, but it offers flexibility in training custom models.\n",
    "\n",
    "    Microsoft LUIS:\n",
    "\n",
    "    Setup: Easy to set up via Azure, but requires an Azure account and knowledge of LUIS application management.\n",
    "\n",
    "    Integration: Good integration with Azure services, and easy to access via REST API or SDK.\n",
    "\n",
    "    OpenAI GPT:\n",
    "\n",
    "    Setup: Requires obtaining an API key from OpenAI and using it with an HTTP client to send requests.\n",
    "\n",
    "    Integration: Simple integration via API calls; however, you need a stable internet connection to use the service.\n",
    "\n",
    "Ease of Use:\n",
    "    Google Dialogflow:\n",
    "\n",
    "    Pros:\n",
    "\n",
    "    Graphical interface for building intents and entities.\n",
    "\n",
    "    Automatic intent detection and response generation.\n",
    "\n",
    "    Cons:\n",
    "\n",
    "    Limited customization compared to Rasa.\n",
    "\n",
    "    Rasa NLU:\n",
    "\n",
    "    Pros:\n",
    "\n",
    "    Completely open-source and customizable.\n",
    "\n",
    "    Allows you to define intents, entities, and actions manually.\n",
    "\n",
    "    Cons:\n",
    "\n",
    "    Requires programming knowledge and manual training of models.\n",
    "\n",
    "    Microsoft LUIS:\n",
    "\n",
    "    Pros:\n",
    "\n",
    "    Easy to set up with a web interface.\n",
    "\n",
    "    Integrates well with Microsoft Azure services.\n",
    "\n",
    "    Cons:\n",
    "\n",
    "    Limited flexibility compared to Rasa.\n",
    "\n",
    "    Requires knowledge of Azure to fully leverage its power.\n",
    "    OpenAI GPT:\n",
    "\n",
    "    Pros:\n",
    "\n",
    "    No setup needed for intent definition; you can simply send any input to the model, and it will generate a response.\n",
    "\n",
    "    Cons:\n",
    "\n",
    "    Responses might be generic and not always accurate for intent-based chatbots.\n",
    "\n",
    "    Requires access to the OpenAI API, which can be costly.\n",
    "\n",
    "Intent Recognition:\n",
    "    Google Dialogflow:\n",
    "\n",
    "    Accuracy: High accuracy for common intents and entities, but may struggle with very specific or domain-specific intents.\n",
    "\n",
    "    Customization: Limited ability to customize training data for niche intents.\n",
    "\n",
    "    Rasa NLU:\n",
    "\n",
    "    Accuracy: Very high when properly trained. Allows for highly specific intent recognition.\n",
    "\n",
    "    Customization: Extremely customizable; you can tailor training data and models to fit any domain.\n",
    "\n",
    "    Microsoft LUIS:\n",
    "\n",
    "    Accuracy: High accuracy for general intents, but may struggle with complex or niche domains.\n",
    "\n",
    "    Customization: Customizable, but somewhat limited compared to Rasa.\n",
    "\n",
    "    OpenAI GPT:\n",
    "\n",
    "    Accuracy: Very accurate for conversational responses, but not designed specifically for intent recognition.\n",
    "\n",
    "    Customization: Very little customization for intent recognition, since it operates as a general-purpose language model.\n",
    "\n",
    "Response Generation:\n",
    "    Google Dialogflow:\n",
    "\n",
    "    Response Quality: Can provide predefined responses, but the quality of the response is only as good as the training data.\n",
    "\n",
    "    Rasa NLU:\n",
    "\n",
    "    Response Quality: You must define the response logic (action) yourself, so it can be highly tailored and controlled.\n",
    "\n",
    "    Microsoft LUIS:\n",
    "\n",
    "    Response Quality: LUIS generates intents, but you need to connect it to a backend service to determine the response.\n",
    "\n",
    "    OpenAI GPT:\n",
    "\n",
    "    Response Quality: Excellent conversational quality, but the responses are sometimes overly general or off-topic depending on the context.\n",
    "\n",
    "Performance and Latency:\n",
    "    Google Dialogflow:\n",
    "\n",
    "    Performance: Fast response times (usually under 1 second).\n",
    "\n",
    "    Latency: Can handle high throughput, especially with Google Cloud infrastructure.\n",
    "\n",
    "    Rasa NLU:\n",
    "\n",
    "    Performance: Fast when running locally, but latency might be higher when deployed on cloud servers.\n",
    "\n",
    "    Latency: Depends on your server and configuration.\n",
    "\n",
    "    Microsoft LUIS:\n",
    "\n",
    "    Performance: Can handle high throughput, but depends on Azure’s current load and configuration.\n",
    "\n",
    "    Latency: Response time can vary depending on usage and cloud conditions.\n",
    "\n",
    "    OpenAI GPT:\n",
    "\n",
    "    Performance: Fast for small requests, but can experience delays during high load.\n",
    "\n",
    "    Latency: It can take a few seconds depending on server load and model size.\n",
    "\n",
    "Customization:\n",
    "    Google Dialogflow:\n",
    "\n",
    "    Customization: Limited in terms of modifying underlying algorithms. You can customize entities and intents but not the core engine.\n",
    "\n",
    "    Rasa NLU:\n",
    "\n",
    "    Customization: Highly customizable. You can define your models, intents, and responses, and even modify the underlying pipeline.\n",
    "\n",
    "    Microsoft LUIS:\n",
    "\n",
    "    Customization: Customizable for intents and entities but limited in other areas.\n",
    "\n",
    "    OpenAI GPT:\n",
    "\n",
    "    Customization: Very limited in terms of training for specific intents, but responses can be tailored via prompt engineering.\n",
    "\n",
    "Pricing:\n",
    "    Google Dialogflow:\n",
    "\n",
    "    Free Tier: Offers a free tier with limited usage.\n",
    "\n",
    "    Paid: Paid pricing is based on the number of requests and types of actions.\n",
    "\n",
    "    Rasa NLU:\n",
    "\n",
    "    Free Tier: Completely open-source and free to use.\n",
    "\n",
    "    Paid: Charges apply only for enterprise-level features (e.g., Rasa X).\n",
    "\n",
    "    Microsoft LUIS:\n",
    "\n",
    "    Free Tier: Offers limited free usage.\n",
    "\n",
    "    Paid: Paid pricing based on the number of queries and features.\n",
    "\n",
    "    OpenAI GPT:\n",
    "\n",
    "    Free Tier: No free tier available. Costs based on the number of tokens processed.\n",
    "\n",
    "    Paid: Pricing varies based on usage and model size.\n",
    "\n",
    "Community and Support:\n",
    "    Google Dialogflow:\n",
    "\n",
    "    Community: Large community, but support is mainly via the Google Cloud platform.\n",
    "\n",
    "    Rasa NLU:\n",
    "\n",
    "    Community: Very active open-source community with lots of resources and contributions.\n",
    "\n",
    "    Microsoft LUIS:\n",
    "\n",
    "    Community: Large community within the Microsoft ecosystem. Excellent support via Microsoft Azure.\n",
    "\n",
    "    OpenAI GPT:\n",
    "\n",
    "    Community: Active community, especially for developers leveraging GPT in chatbots. Support is through OpenAI’s platform."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
